{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "\n",
    "Hint: you can use [pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) to scrape the data into a DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with company tickers, names, and the year they were added.\n",
    "2. Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "3. Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records).\n",
    "\n",
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_p_500 = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\") \n",
    "sp500_table = s_p_500[0]\n",
    "sp500_table_interest = sp500_table[[\"Symbol\", \"Security\", \"GICS Sector\",\"Date added\"]]\n",
    "symbols_and_dates = sp500_table[['Symbol','Date added']].copy()\n",
    "#get the number of stocks added each year\n",
    "symbols_and_dates['Date added'] = pd.to_datetime(symbols_and_dates['Date added'])\n",
    "symbols_and_dates['Year'] = symbols_and_dates['Date added'].dt.year\n",
    "added_per_year = symbols_and_dates.groupby('Year').size().reset_index(name='Count')\n",
    "added_per_year = added_per_year.sort_values(by='Count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "added_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional: How many current S&P 500 stocks have been in the index for more than 20 years? \n",
    "# When stocks are added to the S&P 500,\n",
    "# they usually experience a price bump as investors and index funds buy shares following the announcement.\n",
    "current_date = pd.to_datetime('today')\n",
    "long_term_stocks = symbols_and_dates[symbols_and_dates['Date added'] <= current_date - pd.Timedelta(days=365*20)]\n",
    "long_term_count = long_term_stocks['Symbol'].nunique()\n",
    "print(long_term_count)\n",
    "long_term_stocks[['Symbol', 'Date added']].head(10)  # Displaying the first 10 long-term stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance\n",
    "\n",
    "Context: \n",
    "> [Global Valuations: Who's Cheap, Who's Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update) article suggests \"Other regions may be growing faster than the US and you need to diversify.\"\n",
    "\n",
    "Reference: Yahoo Finance World Indices - https://finance.yahoo.com/world-indices/\n",
    "\n",
    "*Additional*: How many of these indexes have better returns than the S&P 500 over 3, 5, and 10 year periods? Do you see the same trend?\n",
    "Note: For simplicity, ignore currency conversion effects.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "major_stock_list = ['^GSPC', '000001.SS','^HSI', '^AXJO', '^NSEI', '^GSPTSE', '^GDAXI', '^FTSE', '^N225', '^MXX','^BVSP']\n",
    "start_date = '2025-01-01'\n",
    "end_date = '2025-05-01'\n",
    "difference = pd.to_datetime(end_date) - pd.to_datetime(start_date)\n",
    "data = pd.DataFrame()\n",
    "for stock in major_stock_list:\n",
    "    try:\n",
    "        ticker = yf.Ticker(stock)\n",
    "        df = ticker.history(period='1d', start=start_date, end=end_date)\n",
    "        df['Symbol'] = stock\n",
    "        df_filtered = df[df['Symbol'] == stock]\n",
    "        df_filtered['ytd_change'] = (df_filtered['Close'].iloc[-1]/df_filtered['Close'] - 1)\n",
    "        df_filtered['ytd_change'] = df_filtered['ytd_change'].fillna(0)  # Fill NaN values with 0\n",
    "        df.loc[df_filtered.index, 'ytd_change'] = df_filtered['ytd_change']\n",
    "        df = df.reset_index()\n",
    "        data = pd.concat([data, df], ignore_index=True, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {stock}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group data by Symbol to work with each index separately\n",
    "# 2. Get first and last trading day for each index\n",
    "# 3. Calculate proper YTD returns\n",
    "\n",
    "# First, let's create a function to calculate YTD returns\n",
    "def calculate_ytd_returns(df_group):\n",
    "    # Sort by date to ensure first is earliest and last is latest\n",
    "    df_sorted = df_group.sort_values('Date')\n",
    "    # Get first and last close price\n",
    "    first_price = df_sorted['Close'].iloc[0]\n",
    "    last_price = df_sorted['Close'].iloc[-1]\n",
    "    # Calculate return\n",
    "    ytd_return = (last_price / first_price) - 1\n",
    "    return pd.Series({'ytd_return': ytd_return, })\n",
    "\n",
    "# Apply the function to each group of Symbol\n",
    "ytd_returns = data.groupby('Symbol').apply(calculate_ytd_returns).reset_index()\n",
    "\n",
    "# Identify the S&P 500 return\n",
    "sp500_return = ytd_returns[ytd_returns['Symbol'] == '^GSPC']['ytd_return'].values[0]\n",
    "\n",
    "# Compare other indices to S&P 500\n",
    "better_than_sp500 = ytd_returns[ytd_returns['ytd_return'] > sp500_return]\n",
    "\n",
    "# Count how many are better (excluding S&P 500 itself)\n",
    "num_better = len(better_than_sp500[better_than_sp500['Symbol'] != '^GSPC'])\n",
    "\n",
    "print(f\"Number of indices with better YTD returns than S&P 500: {num_better}\")\n",
    "print(\"\\nYTD Returns for all indices (sorted):\")\n",
    "print(ytd_returns.sort_values('ytd_return', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytd_returns.sort_values('ytd_return', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=data, x='Date', y='ytd_change', hue='Symbol')\n",
    "plt.title('YTD Change of Major Stock Indices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('YTD Change')\n",
    "plt.legend(title='Symbol', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "\n",
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous prices)\n",
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high × 100\n",
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \n",
    "> * Investors often wonder about the typical length of market corrections when deciding \"when to buy the dip\" ([Reddit discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> * [A Wealth of Common Sense - How Often Should You Expect a Stock Market Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of top 10 largest corrections by drawdown:\n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days\n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days\n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days\n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days\n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days\n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days\n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days\n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical data\n",
    "sp500 = yf.download('^GSPC', start='1950-01-01')['Close']\n",
    "\n",
    "# Identify correction periods\n",
    "all_time_highs = sp500.cummax()\n",
    "sp500['Is_ATH'] = (sp500 == all_time_highs)\n",
    "ath_dates = sp500.index[sp500['Is_ATH']].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corrections = []\n",
    "\n",
    "for i in range(len(ath_dates)-1):\n",
    "    start = ath_dates[i]\n",
    "    end = ath_dates[i+1]\n",
    "    high = all_time_highs.loc[ath_dates[i]].iloc[0]\n",
    "    low = sp500.loc[start:end].min().iloc[0]\n",
    "    \n",
    "    # Calculate drawdown\n",
    "    drawdown = (high - low)/high * 100\n",
    "    if isinstance(drawdown, pd.Series):\n",
    "        drawdown = drawdown.iloc[0]  # Handle series conversion\n",
    "    \n",
    "    if drawdown >= 5:\n",
    "        min_date = sp500.loc[start:end].idxmin().iloc[0]\n",
    "        duration = (min_date - start).days\n",
    "        corrections.append({\n",
    "            'Start Date': start.strftime('%Y-%m-%d'),\n",
    "            'End Date': min_date.strftime('%Y-%m-%d'),\n",
    "            'Duration (Days)': duration,\n",
    "            'Drawdown %': round(drawdown, 1)\n",
    "        })\n",
    "\n",
    "# Create formatted dataframe\n",
    "corrections_df = pd.DataFrame(corrections)\n",
    "print(corrections_df.head(10))\n",
    "corrections_df.sort_values(by='Drawdown %', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrections_df['Duration (Days)'].describe(percentiles=[.25, .5, .75]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_df['Duration (Days)'].plot(kind='hist', bins=10, edgecolor='black')\n",
    "plt.title('Distribution of Correction Durations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "\n",
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS\n",
    "2. Download complete historical price data using yfinance\n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the return as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\" OR \"Surprise (%)>0\")\n",
    "5. Calculate 2-day percentage changes following positive earnings surprises\n",
    "6. Compare the median 2-day percentage change for positive surprises vs. all historical dates\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar - https://finance.yahoo.com/calendar/earnings?symbol=AMZN\n",
    "\n",
    "*Additional*: Is there a correlation between the magnitude of the earnings surprise and the stock price reaction? Does the market react differently to earnings surprises during bull vs. bear markets?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean earnings data\n",
    "earnings = pd.read_csv('../../data/raw_data/ha1_Amazon.csv', sep=';').iloc[:-1, :]  # Exclude the last row which is a summary row\n",
    "earnings['Earnings Date'] = pd.to_datetime(earnings['Earnings Date'].str.split(' at').str[0], errors='coerce')\n",
    "\n",
    "# Clean numeric columns\n",
    "numeric_cols = ['EPS Estimate', 'Reported EPS', 'Surprise (%)']\n",
    "for col in numeric_cols:\n",
    "    earnings[col] = pd.to_numeric(earnings[col].str.replace('[^-.0-9]', '', regex=True), errors='coerce')\n",
    "\n",
    "# Download historical prices\n",
    "amzn = yf.download('AMZN', start='1997-05-15')['Close'].reset_index()\n",
    "amzn.columns = ['Date', 'Price']\n",
    "\n",
    "# Calculate 2-day returns for ALL dates\n",
    "amzn['2_day_pct_change'] =((amzn['Price'].shift(-2) / amzn['Price']) - 1)\n",
    "\n",
    "positive_surprises = earnings[\n",
    "    (earnings['Reported EPS'] > earnings['EPS Estimate']) | \n",
    "    (earnings['Surprise (%)'] > 0)\n",
    "].copy()\n",
    "#\n",
    "\n",
    "dates_to_consider = positive_surprises['Earnings Date'].tolist()\n",
    "# Filter AMZN data for the dates of interest\n",
    "amzn_filtered = amzn[amzn['Date'].isin(dates_to_consider)].copy()\n",
    "\n",
    "#( amzn_filtered['Price'].shift(-2)/amzn_filtered['Price'] -1).median()\n",
    "amzn_filtered['2_day_pct_change'].median()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge earnings dates with price data\n",
    "merged = pd.merge_asof(\n",
    "    earnings.sort_values('Earnings Date'),\n",
    "    amzn.sort_values('Date'),\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Filter positive earnings surprises\n",
    "positive_surprises = merged[\n",
    "    ((merged['Reported EPS'] > merged['EPS Estimate']) | (merged['Surprise (%)'] > 0)) &\n",
    "    merged['2_day_pct_change'].notna()\n",
    "].copy()\n",
    "\n",
    "# Calculate median 2-day percentage changes\n",
    "median_positive = positive_surprises['2_day_pct_change'].median()\n",
    "median_all = amzn['2_day_pct_change'].median()\n",
    "\n",
    "median_positive, median_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge_asof(\n",
    "    earnings.sort_values('Earnings Date'),\n",
    "    amzn.sort_values('Date'),\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward',\n",
    "    tolerance=pd.Timedelta('2D')\n",
    ")\n",
    "positive_surprises = merged[\n",
    "    ((merged['Reported EPS'] > merged['EPS Estimate']) | \n",
    "    (merged['Surprise (%)'] > 0)) &\n",
    "    merged['2_day_pct_change'].notna()\n",
    "]\n",
    "\n",
    "# Calculate comparison metrics\n",
    "all_days_median = amzn['2_day_pct_change'].median()*100\n",
    "positive_surprises_median = positive_surprises['2_day_pct_change'].median()*100\n",
    "\n",
    "print(f\"Median 2-day return after positive surprises: {positive_surprises_median:.2%}\")\n",
    "print(f\"Median 2-day return for all trading days: {all_days_median:.2%}\")\n",
    "\n",
    "# Optional: Display key examples\n",
    "print(\"\\nNotable examples:\")\n",
    "print(positive_surprises[['Earnings Date', 'Surprise (%)', '2_day_pct_change']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "\n",
    "### Question 5.  [Exploratory, optional] Brainstorm potential idea for your capstone project\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Describe the capstone project you would like to pursue, considering your aspirations, ML model predictions, and prior knowledge. Even if you are unsure at this stage, try to generate an idea you would like to explore-such as a specific asset class, country, industry vertical, or investment strategy. Be as specific as possible.\n",
    "\n",
    "*Example: I want to build a short-term prediction model for the US/India/Brazil stock markets, focusing on the largest stocks over a 30-day investment horizon. I plan to use RSI and MACD technical indicators and news coverage data to generate predictions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "For my capstone project, I would like to develop a mid-term prediction model for equity markets in both Latin America (specifically Colombia, Brazil, Mexico, Argentina, Chile, Peru) and the United States. My focus will be on forecasting stock returns or index levels over a six-month investment horizon. I am interested in combining traditional technical indicators with macroeconomic variables, particularly each country’s interest rates and inflation rates, to improve predictive power.\n",
    "\n",
    "My goal is to investigate how the interplay between technical signals and local macroeconomic conditions affects market performance, and whether machine learning models can capture these relationships for more robust investment strategies. As a physicist with no formal background in economics, I am motivated to bridge my quantitative skills with financial knowledge, and I look forward to learning more about macroeconomic indicators and their impact on asset prices as I progress through the project.\n",
    "\n",
    "Potential challenges include sourcing reliable macroeconomic and market data for Latin American countries and interpreting the economic context behind the numbers. However, I believe this interdisciplinary approach could yield valuable insights for investors interested in emerging markets and global diversification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "\n",
    "### Question 6. [Exploratory, optional] Investigate new metrics\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Using the data sources we have covered (or any others you find relevant), download and explore a few additional metrics or time series that could be valuable for your project. Briefly explain why you think each metric is useful. This does not need to be a comprehensive list-focus on demonstrating your ability to generate data requests based on your project description, identify and locate the necessary data, and explain how you would retrieve it using Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
